{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "interpreter": {
      "hash": "e3509438d643bb33965a810c83f1e02f5e0b9a25eebb1aa54949cc1616c29330"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-qiINBQSK2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for math\n",
        "import numpy as np\n",
        "# for charts\n",
        "import matplotlib.pyplot as plt\n",
        "# data mainpulation and analysis\n",
        "import pandas as pd"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEPNDWySTKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read and create data frame\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "# FEATURES - indepenten - info for prediction\n",
        "X = dataset.iloc[:, :-1].values\n",
        "# DEPENDENT VARS\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsz2yCebe1R",
        "colab_type": "code",
        "outputId": "1e4cc568-4e51-4b38-9d46-4aa3f15204be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 nan]\n ['France' 35.0 58000.0]\n ['Spain' nan 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYrOQ43XcJR3",
        "colab_type": "code",
        "outputId": "e0873b2a-3b08-4bab-ef0d-15b88858ca44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c93k7ipkSexq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sikit-learn lib with algorithms\n",
        "from sklearn.impute import SimpleImputer\n",
        "# create object out of class\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "# make connection with object and features\n",
        "imputer.fit(X[:, 1:3])\n",
        "# execute\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UgLdMS_bjq_",
        "colab_type": "code",
        "outputId": "254af4e0-681e-47f5-aaa7-b9c6f43258e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hwuVddlSwVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Meta-estimators for building composite models with transformers\n",
        "from sklearn.compose import ColumnTransformer # class\n",
        "# includes scaling, centering, normalization, binarization methods.\n",
        "# one hot encoder turn string of name of country to 3 column that let\n",
        "# ml interact with it as number . make binary vector out of it \n",
        "from sklearn.preprocessing import OneHotEncoder # class\n",
        "# make connection (first : what kind of transformation and which index , second : let other column stay)\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "# execute\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7QspewyeBfx",
        "colab_type": "code",
        "outputId": "5b35feef-7fe2-46ef-ce70-80495f94f4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHCShVyTOYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyhY8-gPpFCa",
        "colab_type": "code",
        "outputId": "7f76ef29-5423-4c3e-cf69-45fbc366a997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXgA6CzlqbCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test set mostly for evaluate the performance of model in new observation \n",
        "from sklearn.model_selection import train_test_split #function \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuwQhFdKrYTM",
        "colab_type": "code",
        "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUrX_Tvcrbi4",
        "colab_type": "code",
        "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSMHiIsWreQY",
        "colab_type": "code",
        "outputId": "5afe91e0-9244-4bf5-ec1b-e3e092b85c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_tW7H56rgtW",
        "colab_type": "code",
        "outputId": "2a93f141-2a99-4a69-eec5-c82a3bb8d36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxjSUXFQqo-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Scaling all vars, all features to make sure they take all values on the same scale \n",
        "#  prevent one feature dominant others which therefore will be neglected by ml model\n",
        "#  feature scaling work on mean of data pool and its better to remove test set before\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# standardisation between -3 and 3 , normalisation between -1 and 1\n",
        "# normalisation when we have normal distribution\n",
        "# standardisation work all the time .\n",
        "# feature scaling happen on train packages on train and test cases .\n",
        "sc = StandardScaler() #rows , columns\n",
        "# don't do feature scaling on dumy vars .\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "# because we dont want new scaler to fit and transform and we want to test case work\n",
        "# with before scaler we only use transform , fit do calc but execs are on top of transforms\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWPET8ZdlMnu",
        "colab_type": "code",
        "outputId": "dea86927-5124-4e2a-e974-2804df9a913c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTXykB_QlRjE",
        "colab_type": "code",
        "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}